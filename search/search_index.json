{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"blog/","title":"Blog","text":""},{"location":"blog/2025/02/28/hello-everyone-this-is-my-first-post/","title":"Hello everyone! This is my first post!","text":""},{"location":"projects/Bluetooth-Reset/","title":"Bluetooth Reset","text":"<p>This is a simple Android development project that I worked on. The outcome is a simple menu with a button to direct the user to the management of the Bluetooth package in the android settings. This application was used for me to quickly access it to force stop my Bluetooth, back then when my phone was faccing issues with it.</p>"},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/","title":"IOT Monitoring / IDS Home Server","text":"<p>This project is a simple home server I had made to monitor IOT devices in my home network for their downtime, as well as catching any possible intrusions into the network. Primarily being a proof of concept, there are some limitations to the product, which I will share about as well. This project is especially helpful in a scenario where there is a lack of admin controls to the router on the network.</p>"},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/#breakdown","title":"Breakdown","text":"<p>Here is the architecture of the project</p> <p> <p>The entire process is hosted on a Raspberry Pi 4 Model B with 8GB of ram. Grafana is an open source analytics and interactive visualization web application, while Loki is a log aggregation system to store and query logs from applications. This repo assumes that Nmap, Grafana and Loki clients have been setup on the machine.</p> <ol> <li> <p>A python script first executes an Nmap command in a 5 mins interval</p> <ul> <li>A Samba share is configured to allow me to modify the scripts through my home computer</li> <li>The following Nmap command is used, the parameter -sn disbales port scan as we only want to know the existence of the devices of the network, while running the command in sudo allows for us to run in privilege mode, getting more info such as the MAC address of the devices:     <pre><code>sudo nmap -sn 192.168.0.0/24\n</code></pre></li> </ul> </li> <li> <p>The script retrieves the list of devices, every device being in the following format:</p> <pre><code>Nmap scan report for L920.Midkemia (192.168.0.70)\nHost is up (0.030s latency).\nMAC Address: 9C:53:22:3E:E9:44 (Unknown)\n</code></pre> </li> <li> <p>While there is an existing solution to use a Promtail client to push logs generated by my python script to Loki, I decided to go with python-logging-loki, which wraps around the exisitng logging library in python and sends logs straight to Loki with the Loki HTTP API</p> </li> <li> <p>Grafana then pulls the logs stored in Loki to be visualised in dashboards and create alerts.</p> </li> </ol>"},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/#dashboard-preview","title":"Dashboard Preview","text":"<p>"},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/#1-top-half-bedroom-lights","title":"1. Top half - Bedroom Lights","text":"<p> <p>From the list of devices retrieved in the automated Nmap scan, Grafana identifies if a list of MAC addresses are present in the scan. These MAC addresses are that of my Wifi-controlled bedroom lights (6 of them). It's absence indicates that the device is experienced a timeout and may not be responsive.</p> <p>In my case, this section is useful as I occasionally experience my lights being unresponsive to commands such as colour change or switching on/off.</p>"},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/#2-bottom-half-nmap-sweeper","title":"2. Bottom half - Nmap Sweeper","text":"<p> <p>More metrics is displayed in this section, showing a trend of the number of devices detected in the network over time, as well the number of outliers.</p> <p>In this case, an outlier refers to a new device detected in the scan that was not present in the previous scan, it can be an indication to new joiners in the network. However, due to the inconsistency in the scan (timeout when trying to reach existing devices etc), better methods should be used to detect outliers to avoid false positives.</p>"},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/#future-improvements","title":"Future Improvements","text":""},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/#1-outlier-detection","title":"1. Outlier detection","text":"<p>Instead of detecting outliers by finding devices that were absent from the previous scan interval, more robust solutions should be used to detect the outlier based off a trend of devices staying on the network in the past few scan intervals.</p> <p>Retaining a list of trusted devices will definitely be helpful in the detection as well.</p>"},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/#2-alerts","title":"2. Alerts","text":"<p>When looking through high volumes of log data, we can overlook abnormal activities such as an untrusted device in the network. In that case, we can create alert rules with Grafana where our admin can be informed of new activities in the network via email or other available contact points.</p>"},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/#other-useful-resources","title":"Other Useful Resources","text":""},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/#creating-daemon-processes-automation","title":"Creating Daemon Processes (Automation)","text":"<p>This Medium article provides a tutorial on setting up a python script as a service through systemctl/systemd</p>"},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/#loki-too-many-outstanding-requests","title":"Loki \"Too Many Outstanding Requests\"","text":"<p>This is a common error when trying to query Loki for logs data. A fix can be seen in Stack Overflow.</p>"},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/#samba-permission-denied","title":"Samba Permission Denied","text":"<p>There was an issue encountered where the Linux permissions conflicted with the Samba user access. This can be fixed through the steps in a forum here.</p>"},{"location":"projects/IOT-monitoring-with-grafana-and-nmap/#entering-virtualenv-via-bash-script","title":"Entering Virtualenv via Bash script","text":"<p>In the start.sh script, before the python script is executed, the script first enters the python virtual environment to access the required modules in the python script. </p> <ul> <li>Entering venv in CLI</li> </ul> <p>However, when doing it in a Bash script, specify <code>#!/bin/bash</code> in the first line. The final script should look like this:</p> <pre><code>#!/bin/bash\n\npython3 -m venv /path/to/ids/.venv\nsource /path/to/ids/.venv/bin/activate\npython3 /path/to/ids/nmap.py\n</code></pre>"},{"location":"projects/Pico-Macro-Deck-Prototype/","title":"Pico Macro Deck Prototype","text":"<p> This simple interface comprises of a Raspberry Pico, 2 button inputs and an Adafruit SH1106 I2C controller. This project leverages the following Repositories: * Adafruit CircuitPython Display Text * Adafruit CircuitPython Display Layout * Adafruit CircuitPython DisplayIO SH1106 * Adafruit CircuitPython HID</p>"},{"location":"projects/Pico-Macro-Deck-Prototype/#pinouts","title":"Pinouts","text":"I2C Pico SCL GP21 SDA GP20 GND GND VCC 3V3(OUT)"},{"location":"projects/Pico-Macro-Deck-Prototype/#functionalities","title":"Functionalities","text":"<p>The functions are straightforward:</p> <ul> <li>Button 1 cycles between different macros configured in <code>code.py</code></li> <li>Button 2 executes the selected macro</li> </ul>"},{"location":"projects/Pico-Macro-Deck-Prototype/#adding-new-macros","title":"Adding new macros","text":"<p>A new function can be defined in <code>code.py</code> as such: <pre><code>def hiberate():\n    kbd.send(Keycode.WINDOWS, Keycode.R)\n    time.sleep(0.1)\n    KeyboardLayoutUS(kbd).write('shutdown /h')\n    kbd.send(Keycode.ENTER)\n    return 'Hibernating...'\n    # The return value would be the text displayed after the macro has been executed\n</code></pre></p> <p>the <code>text</code> dictionary should just be updated accordingly to map the new function, where the key would be the title of the macro displayed on the screen. <pre><code>text = {'Say Hi': hello,\n        'Random number from 0 to 9': rand,\n        'CTRL+ALT+DEL': ctrlaltdel,\n        'Hiberate PC': hiberate}\n</code></pre></p>"},{"location":"projects/Pico-Macro-Deck-Prototype/#macros-currently-in-codepy","title":"Macros currently in <code>code.py</code>","text":""},{"location":"projects/Pico-Macro-Deck-Prototype/#hello","title":"<code>hello()</code>","text":"<p>Sends keystrokes of 'hello' into your computer.</p>"},{"location":"projects/Pico-Macro-Deck-Prototype/#rand","title":"<code>rand()</code>","text":"<p>Sends a keystroke of a random integer into your computer.</p>"},{"location":"projects/Pico-Macro-Deck-Prototype/#ctrlaltdel","title":"<code>ctrlaltdel()</code>","text":"<p>Opens the menu.</p>"},{"location":"projects/Pico-Macro-Deck-Prototype/#hibernate","title":"<code>hibernate()</code>","text":"<p>Hibernates the PC.</p>"},{"location":"projects/ic-buddy-bot/","title":"IC Buddy Bot","text":"<p>A telegram bot that aims to assist any IC or appointment holders in generic tasks.</p>"},{"location":"projects/ic-buddy-bot/#features","title":"Features","text":"<ul> <li>Parade state validator</li> <li>SBA roster generator</li> </ul>"},{"location":"projects/in-the-loop/","title":"In the loop","text":"# In The Loop  A Telegram-based newsletter bot to stay connected with friends, inspired by [Letterloop](https://www.letterloop.co/)"},{"location":"projects/in-the-loop/#about-this-project","title":"About this project","text":"<p>For a couple of months, Letterloop allowed me to stay connected with my friends and be in the know of what they were up too at different stages of our lives. We received monthly promptings to update on our lives on a website, before our responses get collated and sent back to us as newsletters showcasing our month for us to keep and enjoy.</p>"},{"location":"projects/in-the-loop/#my-issue","title":"My issue","text":"<p>Since it was a lighthearted activity and not something we were extremely invested in, it was hard for us to continue with the monthly subscription to be able to use the service.</p> <p>Having some time on my hands, I decided to take that opportunity to recreate my version of Letterloop, with modifications such as allowing users to subscribe to it through a Telegram group, rather than submitting their emails. It is a small scale project and not designed to handle high volumes of traffic as compared to the original Letterloop. </p>"},{"location":"projects/in-the-loop/#project-structure","title":"Project structure","text":""},{"location":"projects/in-the-loop/#telegram-interface","title":"Telegram interface","text":"<p>A Python-based telegram bot is created and dockerized, it's main functionality is to allow users in a group chat to subscribe to the service, before sending them custom links to key in their responses monthly. </p> <p>Dockerizing the Python script allows greater flexibility and scalability when I host this job on my home server with other running jobs.</p>"},{"location":"projects/in-the-loop/#web-hosting","title":"Web-hosting","text":"<p>I hosted a web application on the AWS EC2 free instance, it is a <code>t2.micro</code> instance, but functions like a charm for the scale of my project.</p> <p>I followed this guide in order to deploy my NodeJS application on a free EC2 instance on AWS.</p> <p>I decided to create the web application using NodeJS, which was something I was not familiar with and was willing to learn. So far, it has brought me me great pain debugging.</p>"},{"location":"projects/in-the-loop/#want-to-try-it","title":"Want to try it?","text":"<p>I released the code here for learning purposes and for my personal reference in the future. If you would like to try it, you can check it out here: https://t.me/in_the_loop_bot</p> <p>After bringing up the start menu in the group and subscribing to the newsletter, every user should privately message the bot. This is because the bot is unable to initiate a conversation with a user as part of Telegram's security features.</p> <p>This project is just a POC and is not responsible for any tamperment or loss of data. Happy looping!</p>"},{"location":"projects/neural-network-fall-detector/","title":"Neural Network Fall Detection","text":"<p>This project aimed to be a fall detection and alert system based on machine-learning capabilities. Its concept aimed to be a simple alternative to the attachment of physical devices and sensors on elderly patients with high tendancy of falling and causing harm to themselves. </p> <p>While exisiting hardware has remained as a reliable solution in the market, not all medical centres or households are able to afford it for all their patients who need it, and not all patients are medically fit to have such devices around them or attached to them, such as those suffering from dementia with inabilities of voicing out any form of discomfort or pain.</p>"},{"location":"projects/neural-network-fall-detector/#how-does-it-work","title":"How does it work?","text":"<ol> <li> <p>Mediapipe Pose library is first used to get the coordinates of different points on a body captured within a video input. The following image shows the Pose Landmark Model taken from Mediapipe docs.</p> <p> <p>Pose Landmark Model used to identify the coordinates throughout a subject's body.</p> <li> <p>All 33 coordinates are then fed into my prediction model to determine whether our subject is in a fallen state or not.</p> <ul> <li>Although 33 coordinates are taken in as our input data, our tensor shape takes in 99 input values since each coordinate has x, y and z values.</li> </ul> <p>What is displayed when a subject falls:</p> <p> <p>What is displayed when a subject has not fallen:</p> <p> <li> <p>The third component is in development where our recepients would be notified should a fall be detected in a live video feed.</p> </li>"},{"location":"projects/neural-network-fall-detector/#studying-our-prediction-model","title":"Studying our prediction model","text":"<p>When we retrieve a summary of our fall prediction model, we get the following information:</p> <pre><code>Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                Output Shape              Param #   \n=================================================================\ndense (Dense)               (None, 99)                9900\n\ndense_1 (Dense)             (None, 128)               12800\n\ndense_2 (Dense)             (None, 2)                 258\n\n=================================================================\nTotal params: 22,958\nTrainable params: 22,958\nNon-trainable params: 0\n_________________________________________________________________\n</code></pre> <p>As mentioned above, the 99 input features are the xyz coordinates of each of our 33 identified points on our Pose Landmark model. Thus, that determines our input layer with its given shape.</p> <p>As we proceed to the second layer, Sigmoid will be used as our activation function as we require our output for our final layer to be between 0 and 1, as a form of probability for each of our possible outputs (fall or no fall).</p> <p> <p>Activation functions in neural networks explained here</p> <p>For our final layer, we give it a size of 2, for each of the possible outcomes, whether our subject has fallen or not. Using Numpy, we get the feature with the highest score, which also tells us the output we are looking for.</p>"},{"location":"projects/neural-network-fall-detector/#training","title":"Training","text":"<p>The dataset was trained with two videos, one with myself maneuvering between possible postures after a patient would have fallen on the ground, as well as another one casually walking or bending over, where no fall would have been detected.</p> <p>A maximum of 5000 frames were extracted from each video and fed into our Mediapipe Pose detection to retrieve its Pose Landmark values, before being compiled into a bytes file (dataset.bytes). This dataset was then used to build and train our neural network.</p>"},{"location":"projects/neural-network-fall-detector/#future-developments","title":"Future developments","text":"<ul> <li>Add code that allows users to be notified of a detected fall, as well as a snapshot of the frame with the predicted fall. This can be acheived through existing open-source APIs such as Discord.</li> </ul>"},{"location":"projects/web-scraping-api-project/","title":"Web-Scraping Booking Alert Project","text":"<p>The code provided was made specific to the use-case of my own and would be helpful as an example of a functional API that scrapes a website and alert its user about the latest information through the usage of APIs from other communication platforms.</p> <p>While it was functional, it was hosted on a server at DigitalOcean to constantly query and send updates on a booking situation in a particular website to my mobile phone via Discord for a prompt alert to secure my bookings.</p> <p>This use-case can be helpful in school projects that require the concepts of web-scraiping, building of APIs, and integration with other existing APIs. </p>"},{"location":"projects/web-scraping-api-project/#how-does-it-function","title":"How does it function?","text":"<ol> <li> <p>discordExtension.py</p> <ul> <li>Authenticates itself into the targetted website</li> <li>Queries website for information</li> <li>Sends the information to the user via discord</li> </ul> </li> <li> <p>findPracticals.py</p> <ul> <li>Contains the main functions needed to<ul> <li>Authenticate the API script into the targetted website</li> <li>Query the website for information</li> <li>Attempts a re-login whenever a session is expired</li> </ul> </li> </ul> </li> <li>html_js_extract.py<ul> <li>Utilises Selenium's automated testing to receive a DOM body with a valid Google Captcha key for authentication</li> </ul> </li> <li>pass_from_config.py<ul> <li>Functions that parse authentication information from a config file to the main code</li> </ul> </li> </ol> <p></p>"},{"location":"projects/web-scraping-api-project/#train-of-thoughts","title":"Train of thoughts","text":"<p>The objective of this project was to scrape a booking website of a driving school I was enrolled in to retrieve data on the latest booking slots for driving lessons.</p> <p>My problem statement:</p> <p>It was a hassle to constantly login to the school portal and check on the latest booking slots. Normally, slots would have been taken up by other students by the time I login to see the slots.</p> <p>The solution:</p> <p>Automate a script that authenticates me into the portal and query for the latest booking slots before updating me via Discord.</p> <p>Breaking down the problem, I came to conclusion on the resources I needed:</p> <p>All scripts will be written in Python for flexibility and convenience. As for the modules used, I ended up using the following,</p> <ul> <li> <p>Python Requests</p> <ul> <li>Perform both POST and GET requests programmatically to our target website and store cookies and user data into session objects</li> </ul> </li> <li> <p>BeautifulSoup</p> <ul> <li>Scraping of HTML body from HTTP requests to extract important information such as the request verification token from the HTML body</li> </ul> </li> <li> <p>Selenium </p> <ul> <li>Automatically flashing our webpage and retrieving a recaptcha token for authentication (it was impossible to retrieve the token from the HTML body via web-scraping or launching the browser in headless mode)</li> </ul> </li> <li> <p>Chromedriver.py </p> <ul> <li>Ensure that the Chrome drivers used for Selenium was up-to-date</li> </ul> </li> <li> <p>Configparser </p> <ul> <li>Conveniently set necessary config information, such as that needed to authenticate ourselves into the target website</li> </ul> </li> <li> <p>Discord.py </p> <ul> <li>A Discord API will be used so that the information retrieved from the website can be sent conveniently to my phone via a channel message</li> </ul> </li> </ul> <p>I ended up hosting my script on a Linux Debian server via DigitalOcean. After creating a server instance, I configured a GUI and accessed it via a remote desktop. Although SSH would have been a more practical and secured option, at the time of testing, I needed a GUI to flash my browser and \"trick\" the recaptcha into giving me an authentication key.</p>"},{"location":"projects/web-scraping-api-project/#authentication","title":"Authentication","text":"<p>Observing the login form in the webpage's HTML, aside from the login ID and password, two other pieces of information were needed:</p> <p>The first was a Request Verification token, which randomly generates in a hidden input field in the login form upon page load. Using the BeautifulSoup library in python, I was able to retrieve the token value to be used in the request payload in order to establish a user session for the program. </p> <p>The second information needed was a google Captcha key. This however was very difficult to achieve through the same means as the web-scraping technique used previously. </p> <p>Google Captcha key is issued via an external script on the webpage. Thus, using the python get request, it is not possible to retrieve the key value in the DOM body as the script has not been executed. Even rendering the page will not allow the script to retrieve the key since the render function might not support the execution of external scripts or API scripts. Using selenium, the browser driver will be able to load the HTML content after the javascripts have been fully executed, utilizing the capabilities of automated testing.</p> <p>However, using headless testing (meaning that the chrome driver of selenium runs in the background), Google Captcha keys appear to be invalid. It may be due to the lack of a \"normal\" browser for Google to assign cookies or verify the client.</p> <p>Thus the final solution is to utilize automated testing from selenium to retrieve the HTML elements after script execution, before passing the retrieved key over to the bot for form validation. The compromise is that the chrome driver window will appear for a second before minimizing and closing after the key has been retrieved.</p>"},{"location":"projects/web-scraping-api-project/#querying-of-data","title":"Querying of data","text":"<p>After solving the login segment, I had to figure out how the webpage was queried in order to retrieve information on the latest lesson slots. After a lot of research and inspection, it turns out that a POST request is made via Ajax upon a button-click event to be displayed on the webpage. Thus I replicated the request on my script to retrieve the same information.</p> <p>The Ajax request submitted the entire HTML form body in its serialized state in order to get the booking information. By process of elimination, I figured out which form data was needed and which one was not in order to get the target information. Eventually, I was able to receive a response with the booking information I needed to be sent to me automatically.</p>"},{"location":"projects/web-scraping-api-project/#sending-updates-to-the-user","title":"Sending updates to the user","text":"<p>After the information has been retrieved from the website, I created a script that uses the Python Discord API which allows me to create my own Discord bot and set commands and send messages to my server. Thus, when information is received from the website, the bot will update me on the latest booking slots via a text channel. I also created it in a way that the script can be paused or resumed via commands sent by me to the bot.</p>"},{"location":"blog/archive/2025/","title":"2025","text":""}]}